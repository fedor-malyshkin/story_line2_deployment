<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<configuration>
  <property>
    <name>hive.exec.scratchdir</name>
    <value><%= $storyline_infra::hive::hive_scratchdir -%></value>
    <description>HDFS root scratch dir for Hive jobs which gets created with write all (733) permission. For each connecting user, an HDFS scratch dir: ${hive.exec.scratchdir}/&lt;username&gt; is created, with ${hive.scratch.dir.permission}.</description>
  </property>
  <property>
    <name>hive.exec.local.scratchdir</name>
    <value><%= $storyline_infra::hive::dir_data -%>/local_scratchdir</value>
    <description>Local scratch space for Hive jobs</description>
  </property>
  <property>
    <name>hive.downloaded.resources.dir</name>
    <value>${java.io.tmpdir}/${hive.session.id}_resources</value>
    <description>Temporary local directory for added resources in the remote file system.</description>
  </property>
  <property>
    <name>hive.metastore.warehouse.dir</name>
    <value><%= $storyline_infra::hive::hive_warehouse -%></value>
    <description>location of default database for the warehouse</description>
  </property>
  <property>
    <name>hive.metastore.uris</name>
    <value>thrift://<%= $storyline_infra::hive::metastore_hostname -%>:9083</value>
    <description>Thrift URI for the remote metastore. Used by metastore client to connect to remote metastore.</description>
  </property>
  <property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value><%= $storyline_infra::hive::metastore_password -%></value>
    <description>password to use against metastore database</description>
  </property>
  <property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:mysql://<%= $storyline_infra::hive::metastore_hostname -%>/metastore?useLegacyDatetimeCode=false&amp;serverTimezone=UTC</value>
    <description>
      JDBC connect string for a JDBC metastore.
      To use SSL to encrypt/authenticate the connection, provide database-specific SSL flag in the connection URL.
      For example, jdbc:postgresql://myhost/db?ssl=true for postgres database.
    </description>
  </property>
  <property>
    <name>hive.querylog.location</name>
    <value><%= $storyline_infra::hive::dir_data -%>/structured_logs</value>
    <description>Location of Hive run time structured log file</description>
  </property>
  <property>
    <name>hive.server2.logging.operation.log.location</name>
    <value><%= $storyline_infra::hive::dir_data -%>/operation_logs</value>
    <description>Top level directory where operation logs are stored if logging functionality is enabled</description>
  </property>
  <property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>com.mysql.cj.jdbc.Driver</value>
    <description>Driver class name for a JDBC metastore</description>
  </property>
  <property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>hive</value>
    <description>Username to use against metastore database</description>
  </property>
  <property>
    <name>hive.server2.transport.mode</name>
    <value>http</value>
    <description>
      Expects one of [binary, http].
      Transport mode of HiveServer2.
    </description>
  </property>
  <property>
    <name>hive.server2.thrift.bind.host</name>
    <value><%= $storyline_infra::hive::metastore_hostname -%></value>
    <description>Bind host on which to run the HiveServer2 Thrift service.</description>
  </property>
  <property>
    <name>hive.server2.enable.doAs</name>
    <value>false</value>
    <description>
      Setting this property to true will have HiveServer2 execute
      Hive operations as the user making the calls to it.
    </description>
  </property>
  <property>
    <name>hive.default.fileformat</name>
    <value>parquet</value>
    <description>
      Expects one of [textfile, sequencefile, rcfile, orc, parquet].
      Default file format for CREATE TABLE statement. Users can explicitly override it by CREATE TABLE ... STORED AS [FORMAT]
    </description>
  </property>
  <property>
    <name>hive.default.fileformat.managed</name>
    <value>parquet</value>
    <description>
      Expects one of [none, textfile, sequencefile, rcfile, orc, parquet].
      Default file format for CREATE TABLE statement applied to managed tables only. External tables will be
      created with format specified by hive.default.fileformat. Leaving this null will result in using hive.default.fileformat
      for all tables.
    </description>
  </property>
  <property>
    <name>hive.server2.webui.host</name>
    <value>0.0.0.0</value>
    <description>The host address the HiveServer2 WebUI will listen on</description>
  </property>
  <property>
    <name>hive.server2.webui.port</name>
    <value>10002</value>
    <description>The port the HiveServer2 WebUI will listen on. This can beset to 0 or a negative integer to disable the web UI</description>
  </property>
</configuration>
