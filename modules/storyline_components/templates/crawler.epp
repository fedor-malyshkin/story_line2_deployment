server:
  port: <%= $storyline_components::crawler::app_port %>

config:
  # Количество потоков на сайт (лучше не более 4)
  crawler_per_site: 1
  # Папка со скриптами для парсинга контента сайтов
  crawler_script_dir: "<%= $storyline_components::crawler::dir_scripts -%>"
  # Каталог для сохранения данных о результатах парсинга сайта (для каждого сайта
  # создается подпапка с именем домена для хранения соотвествующих данных)
  crawler_storage_dir: "<%= $storyline_components::crawler::dir_sites_db -%>"
  # строка подключения к MongoDB для сохранения результатаов анализа
  mongodb_connection_url: "<%= $storyline_components::crawler::mongodb_connection_url -%>"


  # Блок с настройками для анализируемых сайтов
  parse_sites:
    # На каждый сайт. Название домена (будет использоваться для идентфикации и записи в БД)
    - source: bnkomi.ru
    # На каждый сайт. стартовая страница для парсинга
      seed: http://bnkomi.ru
      cron_schedule: "0 0/5 7-23 * * ?" # Fire every 5 minutes

  feed_sites:
    # На каждый сайт. Название домена (будет использоваться для идентфикации и записи в БД)
    - source: komiinform.ru
      # На каждый сайт. стартовая страница для парсинга
      feed: http://komiinform.ru/rss/news/
      # Расписание в формате cron (http://www.quartz-scheduler.org/documentation/quartz-2.x/tutorials/crontrigger.html)
      cron_schedule: "0 0/5 7-23 * * ?" # Fire every 5 minutes

      # Metrics reporting
  influxdb_metrics:
    enabled: true
    influxdb_host: "<%= $storyline_components::crawler::influxdb_host -%>"
    influxdb_port: <%= $storyline_components::crawler::influxdb_port %>
    influxdb_db: "<%= $storyline_components::crawler::influxdb_db -%>"
    influxdb_user: "<%= $storyline_components::crawler::influxdb_user -%>"
    influxdb_password: "<%= $storyline_components::crawler::influxdb_password -%>"
    reporting_period: 30
    log_reporting_period: 300
